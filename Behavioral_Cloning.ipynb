{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steering Angle Prediction using Keras\n",
    "This project is to build a deep neural network to predict steering angle.<br>\n",
    "Data set: use the <a href=\"https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip\">sample data for track 1</a> provided by Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile\n",
    "\n",
    "if not isfile('data.zip'):\n",
    "    urlretrieve('https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip','data.zip')\n",
    "\n",
    "print('data downloaded.')\n",
    "\n",
    "# unzip the data\n",
    "import zipfile\n",
    "if not isfile('data'):\n",
    "    with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "        \n",
    "print(\"file unzipped\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parse the csv file and pack into pickle for future use\n",
    "import csv\n",
    "from os.path import isfile\n",
    "import pickle\n",
    "\n",
    "if not isfile(\"log.p\"):\n",
    "    log = []\n",
    "    with open('data/driving_log.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        # skip the first row\n",
    "        reader.__next__()\n",
    "        # loop through all entry\n",
    "        for line in reader:\n",
    "            record = []\n",
    "            record.append(\"data/\"+line[0].strip())\n",
    "            record.append(\"data/\"+line[1].strip())\n",
    "            record.append(\"data/\"+line[2].strip())\n",
    "            record.append(float(line[3]))\n",
    "            log.append(record)\n",
    "    with open('log.p', 'wb') as file:\n",
    "        pickle.dump(log, file)\n",
    "        print(\"log saved\")\n",
    "else:\n",
    "    with open('log.p', 'rb') as file:\n",
    "        log = pickle.load(file)\n",
    "        print(\"log loaded\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation and Data generator\n",
    "1.random shift<br>\n",
    "2.random brightness<br>\n",
    "3.random shadow<br>\n",
    "4.random flip<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data augmentation helper functinos\n",
    "# functions borrow from Vivek Yadav's post\n",
    "# https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9#.ub3zjjxme\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# random shift\n",
    "def random_shift(image,angle,trans_range):\n",
    "    # Translation\n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    tr_y = 40*np.random.uniform()-40/2\n",
    "    angle = angle + tr_x/trans_range*2*0.2\n",
    "    rows, cols, chan = image.shape\n",
    "    M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "    image = cv2.warpAffine(image, M, (cols,rows))\n",
    "    return image, angle\n",
    "\n",
    "# random brightness\n",
    "def random_brightness(image):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = 0.2+np.random.uniform() # range from 0.2 to 1.2 of original image brightness\n",
    "    image[:,:,2] = image[:,:,2]*random_bright\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_HSV2RGB)\n",
    "    return image\n",
    "\n",
    "# random shadow\n",
    "def random_shadow(image):\n",
    "    top_y = 320*np.random.uniform()\n",
    "    top_x = 0\n",
    "    bot_x = 160\n",
    "    bot_y = 320*np.random.uniform()\n",
    "    image_hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    shadow_mask = 0*image_hls[:,:,1]\n",
    "    X_m = np.mgrid[0:image.shape[0],0:image.shape[1]][0]\n",
    "    Y_m = np.mgrid[0:image.shape[0],0:image.shape[1]][1]\n",
    "    shadow_mask[((X_m-top_x)*(bot_y-top_y) -(bot_x - top_x)*(Y_m-top_y) >=0)]=1\n",
    "    #random_bright = .25+.7*np.random.uniform()\n",
    "    if np.random.randint(2)==1:\n",
    "        random_bright = 0.5\n",
    "        cond1 = shadow_mask==1\n",
    "        cond0 = shadow_mask==0\n",
    "        if np.random.randint(2)==1:\n",
    "            image_hls[:,:,1][cond1] = image_hls[:,:,1][cond1]*random_bright\n",
    "        else:\n",
    "            image_hls[:,:,1][cond0] = image_hls[:,:,1][cond0]*random_bright    \n",
    "    image = cv2.cvtColor(image_hls,cv2.COLOR_HLS2RGB)\n",
    "    return image\n",
    "\n",
    "# random flip\n",
    "def random_flip(image, angle):\n",
    "    flip = np.random.randint(2)\n",
    "    if flip:\n",
    "        image = cv2.flip(image,1)\n",
    "        angle = -angle\n",
    "    return image, angle\n",
    "\n",
    "# img_reader\n",
    "def img_reader(record_id):\n",
    "    cam_pos = np.random.randint(3)\n",
    "    image_path = log[record_id][cam_pos]\n",
    "    # left camera shift angle 0.27, right camera shift angle -0.27\n",
    "    if (cam_pos == 0):# center cam\n",
    "        shift_ang = 0\n",
    "    if (cam_pos == 1): # left cam\n",
    "        shift_ang = 0.27\n",
    "    if (cam_pos == 2): # right cam\n",
    "        shift_ang = -0.27\n",
    "    angle = file_path = log[record_id][3] + shift_ang\n",
    "    image = mpimg.imread(image_path)\n",
    "    \n",
    "    # augmentation pipeline\n",
    "    image = random_shadow(image)\n",
    "    image, angle = random_shift(image, angle, 100)\n",
    "    image = random_brightness(image)\n",
    "    image, angle = random_flip(image, angle)\n",
    "    return image, angle\n",
    "\n",
    "\n",
    "# test case\n",
    "record_id = np.random.randint(len(log))\n",
    "path = log[record_id][0]\n",
    "print(log[record_id][3])\n",
    "image = mpimg.imread(path)\n",
    "plt.figure(0)\n",
    "plt.imshow(image)\n",
    "image, angle = img_reader(record_id)\n",
    "image = image[50:-25,:,:]\n",
    "print(image.shape)\n",
    "plt.figure(1)\n",
    "plt.imshow(image)\n",
    "print(angle)\n",
    "plt.figure(2)\n",
    "plt.imshow(image[:,:,0], cmap=\"gray\")\n",
    "plt.figure(3)\n",
    "plt.imshow(image[:,:,1], cmap=\"gray\")\n",
    "plt.figure(4)\n",
    "plt.imshow(image[:,:,2], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data generator\n",
    "def data_generator(log , batch_size = 250):\n",
    "    batch_images = np.zeros((batch_size, 160, 320, 3))\n",
    "    batch_angle = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        pr_threshold = 0\n",
    "        while(pr_threshold < 0.4):\n",
    "            pr_threshold = np.random.uniform()\n",
    "        for i in range(batch_size):\n",
    "            record_id = np.random.randint(len(log))      \n",
    "            keep_pr = 0\n",
    "            while keep_pr == 0:\n",
    "                image, angle = img_reader(record_id)\n",
    "                if abs(angle)<0.1:\n",
    "                    pr_val = np.random.uniform()\n",
    "                    if pr_val > pr_threshold:\n",
    "                        keep_pr = 1\n",
    "                else:\n",
    "                    keep_pr = 1\n",
    "            batch_images[i] = image\n",
    "            batch_angle[i] = angle\n",
    "        yield batch_images, batch_angle\n",
    "\n",
    "def val_generator(log , batch_size = 200):\n",
    "    batch_images = np.zeros((batch_size, 160, 320, 3))\n",
    "    batch_angle = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        for i in range(batch_size):\n",
    "            angle = 0\n",
    "            while abs(angle)<0.1:\n",
    "                record_id = np.random.randint(len(log)) \n",
    "                cam_pos = 0\n",
    "                image_path = log[record_id][cam_pos]\n",
    "                angle = file_path = log[record_id][3]\n",
    "                image = mpimg.imread(image_path)\n",
    "            image, angle = random_flip(image, angle)\n",
    "            batch_images[i] = image\n",
    "            batch_angle[i] = angle\n",
    "        yield batch_images, batch_angle\n",
    "        \n",
    "# test case\n",
    "gen = data_generator(log)\n",
    "val_gen = val_generator(log, batch_size = 250)\n",
    "print(\"test pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model Graph\n",
    "The model is nearly identical to the Nvidia paper, except in the paper they convert the color space to YUV. Here we only use RGB.<br>\n",
    "Thanks to the tips on udacity formus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.regularizers import l1, l2, activity_l2\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Lambda\n",
    "\n",
    "\n",
    "def resize(image_data):\n",
    "    import tensorflow as tf\n",
    "    return tf.image.resize_images(image_data, (66, 200))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((45, 25), (0, 0)), input_shape=(160, 320, 3), name=\"cropping\"))\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.0, name=\"normalize\"))\n",
    "model.add(Lambda(resize, name=\"resize\"))\n",
    "model.add(Convolution2D(3, 1, 1, init='he_normal', border_mode='valid'))\n",
    "model.add(Convolution2D(24, 5, 5, activation='elu', init='he_normal', border_mode='valid', subsample=(2,2)))\n",
    "model.add(Convolution2D(36, 5, 5, activation='elu', init='he_normal', border_mode='valid', subsample=(2,2)))\n",
    "model.add(Convolution2D(48, 5, 5, activation='elu', init='he_normal', border_mode='valid', subsample=(2,2)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='elu', init='he_normal', border_mode='valid', subsample=(1,1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='elu', init='he_normal', border_mode='valid', subsample=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='elu', init='he_normal'))\n",
    "model.add(Dense(50, activation='elu', init='he_normal'))\n",
    "model.add(Dense(10, activation='elu', init='he_normal'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "Train and save the model.(the models are saved in a folder name \"model\")<br>\n",
    "use Adam optimizer with 0.0001 learning rate.<br>\n",
    "use mse as loss function.<br>\n",
    "training process is conducted on the destop with GeForce GTX 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import rmtree\n",
    "from os import makedirs\n",
    "from os.path import exists\n",
    "\n",
    "# remove the old saved model and create new model folder\n",
    "if exists(\"./model\"):\n",
    "    rmtree(\"./model\")\n",
    "    print(\"removed old model folder\")\n",
    "\n",
    "makedirs(\"./model\")\n",
    "print(\"created new model folder\")\n",
    "\n",
    "# save the training result\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "# model.save_weights(\"model.h5\", True)\n",
    "with open(\"model/model.json\",\"w\") as file:\n",
    "    json.dump(json.loads(model.to_json()), file)\n",
    "print(\"model.json saved\")\n",
    "\n",
    "# open log file\n",
    "with open('log.p', 'rb') as file:\n",
    "    log = pickle.load(file)\n",
    "    print(\"log loaded\")\n",
    "\n",
    "# create call backs to store weights after each epcoh\n",
    "filepath = \"model/model.{epoch:02d}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "callback_list = [checkpoint]\n",
    "    \n",
    "# optimize the model\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "gen = data_generator(log, batch_size=400)\n",
    "val_gen = val_generator(log)\n",
    "history = model.fit_generator(generator=gen, samples_per_epoch=20000, nb_epoch=100, validation_data=val_gen, nb_val_samples = 3000, verbose=1, callbacks=callback_list)\n",
    "print(\"model weight saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning\n",
    "fine tune the model  \n",
    "1.run this block to load the model for fine tuning (model files must reside in the same directory as this notebook)  \n",
    "2.run above block to optimize the model (lower the running rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_file = \"model.json\"\n",
    "weights_file = \"model.h5\"\n",
    "with open(model_file, 'r') as jfile:\n",
    "    model = model_from_json(jfile.read())\n",
    "    print(\"model loaded\")\n",
    "model.load_weights(weights_file)\n",
    "print(\"weight loaded\")\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model\n",
    "visualize the model and save to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# from keras.models import model_from_json\n",
    "# from keras.utils.visualize_util import plot\n",
    "\n",
    "\n",
    "# model_file = \"model.json\"\n",
    "# weights_file = \"model.h5\"\n",
    "# with open(model_file, 'r') as jfile:\n",
    "#     model = model_from_json(jfile.read())\n",
    "#     print(\"model loaded\")\n",
    "# model.load_weights(weights_file)\n",
    "# print(\"weight loaded\")\n",
    "# plot(model, to_file='model.png')\n",
    "# print(\"model plot\")\n",
    "\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "1. create test images\n",
    "2. take test images to visualize how CNN responses to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create a test image\n",
    "## by tuning brightness and adding shadow\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# read image\n",
    "path = \"images/test_img_original.jpg\"\n",
    "test1 = mpimg.imread(path)\n",
    "test2 = mpimg.imread(path)\n",
    "# change brightness\n",
    "test1 = cv2.cvtColor(test1, cv2.COLOR_RGB2HSV)\n",
    "test2 = cv2.cvtColor(test2, cv2.COLOR_RGB2HSV)\n",
    "test1[:,:,2] = test1[:,:,2]*1.3\n",
    "test2[:,:,2] = test2[:,:,2]*0.05\n",
    "test1 = cv2.cvtColor(test1,cv2.COLOR_HSV2RGB)\n",
    "test2 = cv2.cvtColor(test2,cv2.COLOR_HSV2RGB)\n",
    "# add shadow\n",
    "test1 = random_shadow(test1)\n",
    "test2 = random_shadow(test2)\n",
    "mpimg.imsave(\"images/test1.jpg\", test1)\n",
    "mpimg.imsave(\"images/test2.jpg\", test2)\n",
    "print(\"images saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "test1 = mpimg.imread(\"images/test1.jpg\")\n",
    "test2 = mpimg.imread(\"images/test2.jpg\")\n",
    "plt.figure(1)\n",
    "plt.imshow(test1)\n",
    "plt.figure(2)\n",
    "plt.imshow(test1[:,:,0], cmap=\"gray\")\n",
    "plt.figure(3)\n",
    "plt.imshow(test1[:,:,1], cmap=\"gray\")\n",
    "plt.figure(4)\n",
    "plt.imshow(test1[:,:,2], cmap=\"gray\")\n",
    "plt.figure(5)\n",
    "plt.imshow(test2)\n",
    "plt.figure(6)\n",
    "plt.imshow(test2[:,:,0], cmap=\"gray\")\n",
    "plt.figure(7)\n",
    "plt.imshow(test2[:,:,1], cmap=\"gray\")\n",
    "plt.figure(8)\n",
    "plt.imshow(test2[:,:,2], cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load the model\n",
    "with open(\"model.json\",\"r\") as file:\n",
    "    model = model_from_json(file.read())\n",
    "model.load_weights(\"model.h5\")\n",
    "model.summary()\n",
    "\n",
    "# output the images\n",
    "# path = \"images/test1.jpg\"\n",
    "# path = \"images/test2.jpg\"\n",
    "# path = \"images/feature_test.jpg\"\n",
    "path = \"images/road.jpg\"\n",
    "test_image = np.array([mpimg.imread(path)])\n",
    "plt.figure(0)\n",
    "plt.imshow(test_image[0])\n",
    "print(test_image.shape)\n",
    "input_image = test_image\n",
    "get_layer_output = K.function([model.layers[0].input],[model.layers[5].output])\n",
    "layer_output = get_layer_output([input_image])[0]\n",
    "print(layer_output.shape)\n",
    "fig = plt.figure(figsize=(6,6)) # size must match the layer output size\n",
    "for i in range(layer_output.shape[-1]):\n",
    "    ax = fig.add_subplot(12,3,i+1) # layout grid must match the output size\n",
    "    ax.imshow(layer_output[0,:,:,i], cmap=\"gray\")\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
